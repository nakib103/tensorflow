{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto-differanciation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4tI69kh50rv3iGPDIRNqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakib103/tensorflow/blob/master/auto_differanciation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HjbzOFh0YDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtSWtMC90d6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4bb92097-b88d-4220-8dd5-67b3c4a13995"
      },
      "source": [
        "# Tensorflow keep track of operations order during the forward pass. During the backward pass, \n",
        "# TensorFlow traverses this list of operations in reverse order to compute gradients.\n",
        "\n",
        "w = tf.Variable([2., 3.], name='weight')\n",
        "b = tf.Variable([5.], name='bias')\n",
        "x = [[1., 2.],\n",
        "     [5., 8.]]\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  y = x * w + b\n",
        "  loss = tf.reduce_mean(y)\n",
        "\n",
        "[dw, db] = tape.gradient(loss, [w, b])\n",
        "\n",
        "# the shape of the gradient is the shape of the source \n",
        "print(dw, db)\n",
        "\n",
        "# the gradient gives same output format as provided in source\n",
        "my_vars = {\n",
        "    'w' : tf.Variable([2., 3.], name='w'),\n",
        "    'b' : tf.Variable([5.], name='b')\n",
        "}\n",
        "\n",
        "grad = tape.gradient(loss, my_vars)\n",
        "print(grad['w'], grad['b'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1.5 2.5], shape=(2,), dtype=float32) tf.Tensor([1.], shape=(1,), dtype=float32)\n",
            "None None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g07cQEik1JJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b3eab383-eaf0-48f8-b4a5-222b162efd63"
      },
      "source": [
        "# using with a model\n",
        "\n",
        "layer = tf.keras.layers.Dense(2, activation='relu')\n",
        "x = tf.constant([[1., 4., 2.]])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = layer(x)\n",
        "  loss = tf.reduce_mean(y**2)\n",
        "\n",
        "grad = tape.gradient(loss, layer.trainable_variables)\n",
        "print(grad)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
            "array([[ 3.6528475,  6.37145  ],\n",
            "       [14.61139  , 25.4858   ],\n",
            "       [ 7.305695 , 12.7429   ]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.6528475, 6.37145  ], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnHlDXLMPIj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cb7c32c3-f98c-4fe3-e168-4c54ce25ae0e"
      },
      "source": [
        "# what is watched\n",
        "\n",
        "# A trainable variable\n",
        "x0 = tf.Variable(3.0, name='x0')\n",
        "# Not trainable\n",
        "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
        "# Not a Variable: A variable + tensor returns a tensor.\n",
        "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
        "# Not a variable\n",
        "x3 = tf.constant(3.0, name='x3')\n",
        "\n",
        "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "  tape.watch(x2)\n",
        "  y = (x0**2) + (x1**2) + (x2**2)\n",
        "\n",
        "watched = [var.name for var in tape.watched_variables()]\n",
        "print(watched)\n",
        "\n",
        "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
        "\n",
        "for g in grad:\n",
        "  print(g)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "None\n",
            "None\n",
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4_g0lBCQ2ke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70548b92-2191-4bee-bdad-c153e6ed5cec"
      },
      "source": [
        "# gradient for intermediate representation\n",
        "\n",
        "x = tf.Variable([2., 5.])\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  y = x + 1\n",
        "  z = y**3\n",
        "\n",
        "print(tape.gradient(z, y))\n",
        "print(tape.gradient(y, x))\n",
        "del tape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 27. 108.], shape=(2,), dtype=float32)\n",
            "tf.Tensor([1. 1.], shape=(2,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sth8NqN5R5g-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "493b2e59-e060-42bf-ed28-6db55565621d"
      },
      "source": [
        "# if target of the gradient is not scalar the sum of gradient is shown\n",
        "\n",
        "x = tf.Variable(2.)\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x * [1., 5.]\n",
        "\n",
        "print(tape.gradient(y, x))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y0 = x ** 2\n",
        "  y1 = 1 / x\n",
        "\n",
        "print(tape.gradient([y0, y1], x))\n",
        "\n",
        "# for single gradient use Jacobians"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "tf.Tensor(3.75, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caS_YaFcUohX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f859ac0d-c192-4da7-cdce-dcf88a87619a"
      },
      "source": [
        "# control flow -- check\n",
        "# Getting a None gradient\n",
        "\n",
        "# when target and source is not connected\n",
        "x = tf.Variable([3., 5.])\n",
        "y = tf.Variable(5.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = y * y\n",
        "\n",
        "print(tape.gradient(z, x))\n",
        "\n",
        "# for tensors\n",
        "# did calculation outside of tensorflow\n",
        "with tf.GradientTape() as tape:\n",
        "  y = np.mean(x ** 2)\n",
        "  z = tf.reduce_mean(y)\n",
        "\n",
        "print(tape.gradient(z, x))\n",
        "\n",
        "# the target or source tensor are not type float32\n",
        "x = tf.cast(x, tf.int32)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x ** 2\n",
        "\n",
        "print(tape.gradient(y, x))\n",
        "\n",
        "# gradient from stateful object\n",
        "x0 = tf.Variable(3.0)\n",
        "x1 = tf.Variable(0.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  # x1 = x1 + x0        -- this works\n",
        "  x1.assign_add(x0)     # -- this does not work\n",
        "  # The tape starts recording from x1.\n",
        "  y = x1**2   # y = (x1 + x0)**2\n",
        "\n",
        "# This doesn't work.\n",
        "print(tape.gradient(y, x0))   #dy/dx0 = 2*(x1 + x2)\n",
        "\n",
        "# Some operation registered as non-differeantiable or no gradient"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "WARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
            "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
            "None\n",
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmYFWE9lXZjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "776a85b0-2c2d-455b-da2a-97a71b29afd1"
      },
      "source": [
        "# to receive 0 instead of None\n",
        "x = tf.Variable([2., 2.])\n",
        "y = tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = y**2\n",
        "print(tape.gradient(z, x, unconnected_gradients=tf.UnconnectedGradients.ZERO))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}